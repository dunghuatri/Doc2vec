{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# gensim modules\n",
    "from gensim import utils\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from gensim.models import Doc2Vec\n",
    "\n",
    "# numpy\n",
    "import numpy as np\n",
    "\n",
    "# classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# random, itertools, matplotlib\n",
    "import random\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class đọc từng dòng trong file text\n",
    "Mỗi dòng lúc này được xem như một paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabeledLineSentence(object):\n",
    "    def __init__(self, sources):\n",
    "        self.sources = sources\n",
    "        \n",
    "        flipped = {}\n",
    "        \n",
    "        # make sure that keys are unique\n",
    "        for key, value in sources.items():\n",
    "            if value not in flipped:\n",
    "                flipped[value] = [key]\n",
    "            else:\n",
    "                raise Exception('Non-unique prefix encountered')\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for source, prefix in self.sources.items():\n",
    "            with utils.smart_open(source) as fin:\n",
    "                for item_no, line in enumerate(fin):\n",
    "                    yield LabeledSentence(utils.to_unicode(line).split(), [prefix + '_%s' % item_no])\n",
    "    \n",
    "    def to_array(self):\n",
    "        self.sentences = []\n",
    "        for source, prefix in self.sources.items():\n",
    "            with utils.smart_open(source) as fin:\n",
    "                for item_no, line in enumerate(fin):\n",
    "                    self.sentences.append(LabeledSentence(utils.to_unicode(line).split(), [prefix + '_%s' % item_no]))\n",
    "        return self.sentences\n",
    "    \n",
    "    def sentences_perm(self):\n",
    "        shuffled = list(self.sentences)\n",
    "        random.shuffle(shuffled)\n",
    "        return shuffled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class đọc toàn bộ nội dung trong file text\n",
    "Mỗi file text lúc này được xem như một paragraph\n",
    "(tên class này giống hệt tên class trên, chọn 1 trong 2 class thôi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabeledLineSentence(object):\n",
    "    def __init__(self, sources):\n",
    "        self.sources = sources\n",
    "        \n",
    "        flipped = {}\n",
    "        \n",
    "        # make sure that keys are unique\n",
    "        for key, value in sources.items():\n",
    "            if value not in flipped:\n",
    "                flipped[value] = [key]\n",
    "            else:\n",
    "                raise Exception('Non-unique prefix encountered')\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for source, prefix in self.sources.items():\n",
    "            with utils.smart_open(source) as fin:\n",
    "                for item_no, line in enumerate(fin):\n",
    "                    yield LabeledSentence(utils.to_unicode(line).split(), [prefix + '_%s' % item_no])\n",
    "    \n",
    "    def to_array(self):\n",
    "        self.sentences = []\n",
    "        item_no = 0\n",
    "        for source, prefix in self.sources.items():\n",
    "            with open (source, 'r' ,encoding=\"utf8\") as fin:\n",
    "                content=fin.read().replace('\\n', '')\n",
    "                self.sentences.append(LabeledSentence(utils.to_unicode(content).split(), [prefix + '_%s' % item_no]))\n",
    "                item_no = item_no + 1\n",
    "        return self.sentences\n",
    "    \n",
    "    def sentences_perm(self):\n",
    "        shuffled = list(self.sentences)\n",
    "        random.shuffle(shuffled)\n",
    "        return shuffled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xét đường dẫn tới dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sources = {\n",
    "#     'data/movie reviews/test-neg.txt':'TEST_NEG',\n",
    "#     'data/movie reviews/test-pos.txt':'TEST_POS', \n",
    "#     'data/movie reviews/train-neg.txt':'TRAIN_NEG', \n",
    "#     'data/movie reviews/train-pos.txt':'TRAIN_POS',    \n",
    "# }\n",
    "sources = {'data/movie reviews/sample.txt':'SAMPLE',}\n",
    "\n",
    "sentences = LabeledLineSentence(sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xét tham số cho model, build vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\Anaconda3\\lib\\site-packages\\gensim\\models\\doc2vec.py:366: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
      "C:\\Users\\ADMIN\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: DeprecationWarning: Call to deprecated `LabeledSentence` (Class will be removed in 4.0.0, use TaggedDocument instead).\n"
     ]
    }
   ],
   "source": [
    "model = Doc2Vec(min_count=1, window=10, size=100, sample=1e-4, negative=5, workers=7)\n",
    "\n",
    "model.build_vocab(sentences.to_array())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11624063851482092\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "start = timeit.default_timer()\n",
    "model.train(sentences.sentences_perm(), total_examples=model.corpus_count, epochs=1)\n",
    "stop = timeit.default_timer()\n",
    "print(stop - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tìm các từ tương tự với một từ được chọn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('và', 0.2804310917854309),\n",
       " ('gì,', 0.22228646278381348),\n",
       " ('trong', 0.20173762738704681),\n",
       " ('giúp', 0.200840026140213),\n",
       " ('Sĩ,', 0.1889793574810028),\n",
       " ('đến', 0.17195986211299896),\n",
       " ('đạo,', 0.16080373525619507),\n",
       " ('tại', 0.15913458168506622),\n",
       " ('trưng', 0.15474288165569305),\n",
       " ('đáo', 0.14574363827705383)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('hồn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xuất ra vector của doc đã train dựa vào tag của doc đó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.9180225e-03, -4.8305378e-03, -1.9694823e-03, -3.5324236e-03,\n",
       "       -4.8138779e-03,  2.0420922e-03,  1.3339991e-04, -1.3350544e-03,\n",
       "        4.7775670e-03, -2.3314650e-03,  2.9663115e-03,  3.1428877e-03,\n",
       "        3.8340779e-03, -2.1167246e-03,  2.8462938e-04, -8.0698094e-04,\n",
       "        9.6346112e-04, -4.2817262e-03, -7.8171914e-05,  4.2274781e-04,\n",
       "       -2.2594433e-03,  2.3017626e-03,  4.4055484e-04, -9.9025329e-04,\n",
       "        5.1176641e-04,  9.7382365e-04, -3.0314591e-04,  3.4633272e-03,\n",
       "        2.6948685e-03, -4.9898350e-03,  2.2530193e-03, -4.6786955e-03,\n",
       "        4.4693165e-03, -2.1491171e-04, -3.7276214e-03,  1.5188266e-03,\n",
       "       -4.4356044e-03, -4.4513675e-03, -5.8987818e-04, -1.7631575e-03,\n",
       "        7.4141164e-04,  1.3792495e-03,  4.6116393e-03,  2.8618886e-03,\n",
       "       -2.6478977e-03, -3.0130174e-03, -1.7630759e-03,  3.4416362e-03,\n",
       "       -2.2416282e-03, -4.9265227e-03,  2.1799877e-03,  3.8180896e-03,\n",
       "        1.3784419e-03, -3.2269405e-03, -3.9294125e-03,  1.1749561e-03,\n",
       "        2.5398326e-03, -4.2440183e-03, -4.7886083e-04,  1.6157075e-03,\n",
       "        4.3551004e-03,  3.2860402e-03,  1.1621417e-03, -4.7418415e-03,\n",
       "        4.3599438e-03,  1.1705053e-03, -3.5123886e-03, -1.7561361e-03,\n",
       "       -1.5912767e-03,  3.5407417e-03,  2.0042076e-04, -8.9938566e-04,\n",
       "        3.8209381e-03,  2.0192924e-03,  4.5273723e-03,  2.1758729e-03,\n",
       "        2.6330149e-03,  1.2143767e-03,  4.3868897e-03, -1.7949588e-03,\n",
       "        3.1858620e-03,  4.2440733e-03,  3.4060671e-03, -1.2352744e-03,\n",
       "        5.1549916e-05, -4.2167031e-03,  4.5769871e-03,  4.4041155e-03,\n",
       "        3.3590695e-04, -3.5395711e-03,  3.5306178e-03, -2.4398814e-03,\n",
       "       -1.7242916e-03, -3.4697966e-03, -2.9520872e-03,  1.7952236e-03,\n",
       "       -1.4950557e-03, -1.8695515e-03,  2.7186755e-04, -1.1017475e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.docvecs['SAMPLE_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = word_tokenize(\"Chiều nay ăn gì\".lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chiều', 'nay', 'ăn', 'gì']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00275694,  0.00495526,  0.00199558, -0.00445509, -0.00102917,\n",
       "       -0.00241156,  0.0004759 , -0.00012678, -0.00431482, -0.0036441 ,\n",
       "        0.00258672,  0.00284997, -0.00460165,  0.00104439, -0.00312406,\n",
       "       -0.00389866, -0.00148891,  0.00376602, -0.00413713,  0.00251991,\n",
       "       -0.00321384, -0.00280984, -0.00160691,  0.00252372, -0.00105392,\n",
       "       -0.00226692, -0.00375468, -0.00385992, -0.0040242 , -0.00160024,\n",
       "       -0.00307054,  0.00012227, -0.00177097,  0.00282791,  0.00484096,\n",
       "        0.00060721,  0.00101379, -0.00135691, -0.00067399,  0.00388202,\n",
       "        0.00440652,  0.00448975, -0.0023262 ,  0.00370821, -0.00440187,\n",
       "       -0.0039254 , -0.00063182, -0.00470547, -0.00343034,  0.00153152,\n",
       "        0.00468326,  0.00431575, -0.00498626, -0.0007908 , -0.00456093,\n",
       "        0.00463771,  0.00061969,  0.00096   , -0.00073173, -0.00053932,\n",
       "        0.00431567,  0.00078708,  0.00277827, -0.00466654, -0.00116137,\n",
       "        0.00257774, -0.00341603, -0.00271889,  0.00428807, -0.00411362,\n",
       "       -0.00208206,  0.00275577, -0.00314245, -0.00307219,  0.00031064,\n",
       "       -0.00488662, -0.00139535, -0.00099391, -0.00261238,  0.00305016,\n",
       "       -0.00339269, -0.00231052, -0.00157738,  0.0036123 , -0.00183765,\n",
       "       -0.00340001,  0.00059212, -0.00271354,  0.00309063,  0.00412171,\n",
       "        0.00113497,  0.00213972,  0.00038534, -0.00040874, -0.00185343,\n",
       "       -0.00162512,  0.0040503 ,  0.00164367, -0.0020082 ,  0.00166769],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = model.infer_vector(test_data)\n",
    "v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.docvecs.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
